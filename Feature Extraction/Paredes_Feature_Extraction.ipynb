{
    "cells": [
        {
            "cell_type": "code",
            "id": "#VSC-abc01962",
            "metadata": {
                "language": "python"
            },
            "source": [
                "import importlib.util",
                "import subprocess",
                "import sys",
                "import os",
                "",
                "def install_if_missing(package):",
                "    \"\"\"Check if a package is installed; install if missing.\"\"\"",
                "    if importlib.util.find_spec(package) is None:",
                "        print(f\"Installing missing package: {package}\")",
                "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])",
                "",
                "# Use autocorrect for speed",
                "required_packages = [\"pandas\", \"nltk\", \"autocorrect\", \"scikit-learn\", \"tqdm\", \"better-profanity\"]",
                "",
                "for pkg in required_packages:",
                "    install_if_missing(pkg)",
                "",
                "from better_profanity import profanity",
                "profanity.load_censor_words()"
            ]
        },
        {
            "cell_type": "code",
            "id": "#VSC-8d00a822",
            "metadata": {
                "language": "python"
            },
            "source": [
                "import pandas as pd",
                "import re",
                "import nltk",
                "from nltk.corpus import stopwords",
                "from nltk.stem import PorterStemmer, WordNetLemmatizer",
                "from autocorrect import Speller",
                "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer",
                "from tqdm import tqdm",
                "import unicodedata",
                "from nltk.corpus import wordnet"
            ]
        },
        {
            "cell_type": "code",
            "id": "#VSC-1486bea7",
            "metadata": {
                "language": "python"
            },
            "source": [
                "nltk.download('stopwords', quiet=True)",
                "nltk.download('punkt', quiet=True)",
                "nltk.download('wordnet', quiet=True)",
                "nltk.download('omw-1.4', quiet=True)",
                "nltk.download('averaged_perceptron_tagger', quiet=True)",
                "",
                "# Initialize NLP tools",
                "spell = Speller(lang='en')   # autocorrect (fast)",
                "stemmer = PorterStemmer()",
                "lemmatizer = WordNetLemmatizer()",
                "stop_words = set(stopwords.words('english'))",
                "",
                "# Safety: maximum token length to run autocorrect on",
                "MAX_SPELL_TOKEN_LEN = 250 ",
                "",
                "# Ensure output folders exist",
                "os.makedirs(\"lemmatization\", exist_ok=True)",
                "os.makedirs(\"stemmer\", exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "id": "#VSC-87010024",
            "metadata": {
                "language": "python"
            },
            "source": [
                "# Read CSV (fillna so we don't get NaNs)",
                "df = pd.read_csv('Fin_lab-PRProject_dataset.csv', engine='python')",
                "df['review'] = df['review'].fillna(\"\").astype(str)"
            ]
        },
        {
            "cell_type": "code",
            "id": "#VSC-c0b03660",
            "metadata": {
                "language": "python"
            },
            "source": [
                "def remove_punctuation(text):",
                "    \"\"\"Remove punctuation, numbers, HTML/BBCode-like tags, and invisible characters.\"\"\"",
                "    text = \"\" if pd.isna(text) else str(text)",
                "    text = unicodedata.normalize(\"NFKC\", text)",
                "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)",
                "    text = re.sub(r'<.*?>|\\[/?[^\\]]+\\]', '', text)  # remove HTML or BBCode",
                "    text = re.sub(r'[^a-zA-Z\\s-]', '', text)       # allow only letters, spaces, and hyphens",
                "    text = re.sub(r'\\s+', ' ', text).strip()       # collapse whitespace",
                "    return text",
                "",
                "def normalize_repeated_words(text, max_repeat=3):",
                "    \"\"\"",
                "    Reduce repeated glued sequences like 'ihatethisgameihatethisgame' or 'yesyesyes'.",
                "    This function is correct and already limits repeats to max_repeat.",
                "    \"\"\"",
                "    exceptions = {\"ha\", \"he\", \"ho\", \"hihi\", \"hehe\", \"hoho\", \"keke\", \"lol\",",
                "                  \"mama\", \"tata\", \"papa\", \"lala\"}",
                "",
                "    text = text.lower()",
                "",
                "    def repeat_replacer(match):",
                "        word = match.group(1)",
                "        repeated_seq = match.group(2)",
                "        if word in exceptions:",
                "            return match.group(0)",
                "        count = len(repeated_seq) // len(word) + 1",
                "        return \" \".join([word] * min(count, max_repeat))",
                "",
                "    pattern = re.compile(r'(\\b[a-zA-Z]{2,}?)(\\1{2,})', flags=re.IGNORECASE)",
                "    text = pattern.sub(repeat_replacer, text)",
                "",
                "    # Cap spaced repetitions to max_repeat as well",
                "                ... (truncated for brevity) ...
            ]
        },
        {
            "cell_type": "code",
            "id": "#VSC-5adfe1ba",
            "metadata": {
                "language": "python"
            },
            "source": [
                "# --- Main execution ---",
                "tqdm.pandas(desc=\"Spellchecking all reviews\")",
                "df['SpellChecked'] = df['review'].progress_apply(spellcheck_text)"
            ]
        },
        {
            "cell_type": "code",
            "id": "#VSC-509685a8",
            "metadata": {
                "language": "python"
            },
            "source": [
                "tqdm.pandas(desc=\"Applying Lemmatization\")",
                "df['Cleaned_Lemma'] = df['SpellChecked'].progress_apply(lemmatize_text)",
                "",
                "tqdm.pandas(desc=\"Applying Stemming\")",
                "df['Cleaned_Stem'] = df['SpellChecked'].progress_apply(stem_text)"
            ]
        },
        {
            "cell_type": "code",
            "id": "#VSC-591a6b38",
            "metadata": {
                "language": "python"
            },
            "source": [
                "df[['review', 'SpellChecked', 'Cleaned_Lemma']].to_csv('lemmatization/cleaned_reviews_lemmatized.csv', index=False)",
                "df[['review', 'SpellChecked', 'Cleaned_Stem']].to_csv('stemmer/cleaned_reviews_stemmed.csv', index=False)",
                "",
                "print(\"Saved spellchecked, lemmatized, and stemmed reviews.\")"
            ]
        },
        {
            "cell_type": "code",
            "id": "#VSC-d838acb3",
            "metadata": {
                "language": "python"
            },
            "source": [
                "",
                "text_data = df['Cleaned_Lemma'].fillna(\"\")",
                "",
                "print(\"\\nGenerating Bag of Words (BoW) features from Lemmatized text...\")",
                "vectorizer_bow = CountVectorizer(min_df=3, token_pattern=r'[\\w-]+')",
                "bow_features = vectorizer_bow.fit_transform(text_data)",
                "bow_df = pd.DataFrame(bow_features.toarray(), columns=vectorizer_bow.get_feature_names_out())",
                "bow_df.to_csv(\"lemmatization/bow_features_lemmatized.csv\", index=False)",
                "print(\"BoW features saved.\")"
            ]
        },
        {
            "cell_type": "code",
            "id": "#VSC-fd5316bd",
            "metadata": {
                "language": "python"
            },
            "source": [
                "print(\"\\nGenerating TF-IDF features from Lemmatized text...\")",
                "vectorizer_tfidf = TfidfVectorizer(min_df=3, token_pattern=r'[\\w-]+')",
                "tfidf_features = vectorizer_tfidf.fit_transform(text_data)",
                "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=vectorizer_tfidf.get_feature_names_out())",
                "tfidf_df.to_csv(\"lemmatization/tfidf_features_lemmatized.csv\", index=False)",
                "print(\"TF-IDF features saved.\")"
            ]
        },
        {
            "cell_type": "code",
            "id": "#VSC-7c2038c1",
            "metadata": {
                "language": "python"
            },
            "source": [
                "print(\"\\nSample outputs:\")",
                "print(df[['review', 'SpellChecked', 'Cleaned_Lemma', 'Cleaned_Stem']].head())",
                "print(\"\\nProcessing complete.\")"
            ]
        }
    ]
}
